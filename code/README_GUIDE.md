# 英译中神经网络翻译系统 - 多种训练方案

## 🎯 项目概述

这是一个基于深度学习的英译中翻译系统，提供从轻量级到完整版本的多种训练方案，适合不同的硬件配置和时间需求。

## 🚀 快速开始

### 1. 环境准备

```bash
# 安装基础依赖
pip install -r requirements.txt

# 如果需要使用预训练模型，额外安装
pip install transformers
```

### 2. 一键启动

```bash
python start.py
```

这将打开交互式菜单，你可以选择适合的训练方案。

## 📋 训练方案对比

| 方案 | 模型大小 | 参数量 | 序列长度 | 训练时间 | 推荐使用场景 |
|------|----------|--------|----------|----------|--------------|
| 🏃 快速测试 | 最小 | ~2M | 16 tokens | 30分钟 | 快速验证、学习理解 |
| ⚡ 轻量级 | 小 | ~15M | 64 tokens | 1-3小时 | 资源受限、快速原型 |
| 🔥 完整版 | 大 | ~65M | 128 tokens | 8-12小时 | 追求性能、充足资源 |
| 🤖 预训练 | 中等 | ~110M | 64 tokens | 2-4小时 | 更好初始性能 |

## 💡 推荐选择指南

### 如果你是初学者或时间有限
→ **选择快速测试模式 (选项1)**
- 30分钟内看到结果
- 理解整个流程
- 验证环境配置

### 如果你的GPU内存 < 6GB
→ **选择轻量级模式 (选项2)**
- 平衡性能和资源消耗
- 适合大多数情况
- 合理的训练时间

### 如果你有充足的GPU资源和时间
→ **选择完整模式 (选项3)**
- 最佳翻译性能
- 完整的Transformer实现
- 适合研究和生产

### 如果你想要更好的初始性能
→ **选择预训练模式 (选项4)**
- 基于BERT的编码器
- 更少的训练轮次
- 更好的收敛速度

## 🔧 技术架构

### 轻量级模型 (推荐)
```
编码器: 双向LSTM (2层)
解码器: 单向LSTM + 注意力
参数量: ~15M
特点: 快速训练，合理性能
```

### 完整Transformer模型
```
编码器: 6层Transformer编码器
解码器: 6层Transformer解码器
注意力: 8头多头注意力
参数量: ~65M
特点: 完整实现，最佳性能
```

### 预训练模型
```
编码器: BERT多语言模型
解码器: LSTM + 注意力
参数量: ~110M (大部分预训练)
特点: 利用预训练知识，收敛快
```

## 📊 性能预期

### 快速测试模式
- **训练时间**: 30分钟
- **GPU内存**: 2-4GB
- **BLEU分数**: 15-25 (基础水平)

### 轻量级模式
- **训练时间**: 1-3小时
- **GPU内存**: 4-6GB
- **BLEU分数**: 25-35 (实用水平)

### 完整模式
- **训练时间**: 8-12小时
- **GPU内存**: 6-8GB
- **BLEU分数**: 35-45 (较好水平)

## 🛠️ 使用说明

### 自动化训练
```bash
# 直接启动特定模式
python train_lightweight.py    # 轻量级模式
python train.py               # 完整模式
python train_pretrained.py    # 预训练模式
```

### 监控训练
```bash
# 启动TensorBoard
tensorboard --logdir=logs

# 在浏览器中访问
http://localhost:6006
```

### 推理翻译
```bash
# 训练完成后进行推理
python inference.py
```

## 📁 文件结构

```
code/
├── start.py              # 🚀 一键启动脚本
├── train_lightweight.py  # ⚡ 轻量级训练 (推荐)
├── train.py              # 🔥 完整版训练
├── train_pretrained.py   # 🤖 预训练模型训练
├── dataset.py            # 📊 数据处理
├── model.py              # 🧠 Transformer模型
├── inference.py          # 🔍 推理脚本
├── test_data.py          # 🧪 数据测试
└── requirements.txt      # 📦 依赖包
```

## 🎯 训练建议

### 第一次使用
1. 运行 `python start.py`
2. 选择"快速测试模式"
3. 观察训练过程和结果
4. 根据需要选择其他模式

### 资源优化
- **减少batch_size**：如果GPU内存不足
- **减少max_len**：如果希望加快训练速度
- **使用CPU**：如果没有GPU（训练会很慢）

### 提升效果
- **增加训练数据**：使用更多的平行语料
- **数据清洗**：移除质量较差的句子对
- **超参数调优**：调整学习率、模型大小等

## ❓ 常见问题

### Q: GPU内存不足怎么办？
A: 选择快速测试模式，或减少batch_size

### Q: 训练速度太慢？
A: 使用轻量级模式，或减少序列长度

### Q: 翻译质量不满意？
A: 尝试完整模式或预训练模式，增加训练时间

### Q: 如何评估模型性能？
A: 观察验证损失下降，或使用BLEU等指标

## 🔄 模型改进

### 数据增强
- 回译 (Back-translation)
- 同义词替换
- 噪声注入

### 模型优化
- 知识蒸馏
- 模型压缩
- 量化推理

### 训练技巧
- 梯度累积
- 混合精度训练
- 学习率预热

## 📞 技术支持

如果遇到问题：
1. 检查数据文件是否存在
2. 确认GPU内存是否足够
3. 查看错误日志
4. 尝试更简单的配置

---

**💡 建议**: 初次使用请选择"快速测试模式"，熟悉流程后再尝试其他模式。
