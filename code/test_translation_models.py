#!/usr/bin/env python3
"""
ç®€åŒ–çš„ç¿»è¯‘æ¨¡å‹æµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€ŸéªŒè¯T5å’ŒBiLSTMæ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import subprocess
import torch
import numpy as np
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq
import evaluate
from tqdm import tqdm
import time

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    # è®¾ç½®ç½‘ç»œä»£ç†
    result = subprocess.run('bash -c "source /etc/network_turbo && env | grep proxy"', 
                           shell=True, capture_output=True, text=True)
    output = result.stdout
    for line in output.splitlines():
        if '=' in line:
            var, value = line.split('=', 1)
            os.environ[var] = value
    
    # è®¾ç½®Hugging Faceé•œåƒ
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    print("âœ“ ç¯å¢ƒè®¾ç½®å®Œæˆ")

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("ğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        # åŠ è½½è®­ç»ƒæ•°æ®
        start_time = time.time()
        train_dataset = load_dataset("json", data_files="data/translation2019zh_train.json")
        end_time = time.time()
        print(f"âœ“ è®­ç»ƒé›†åŠ è½½å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        sample = train_dataset["train"][0]
        print(f"âœ“ æ•°æ®æ ·æœ¬: {sample}")
        
        # åˆ†å‰²æ•°æ®é›†
        split_datasets = train_dataset["train"].train_test_split(test_size=0.1, seed=42)
        print(f"âœ“ è®­ç»ƒé›†å¤§å°: {len(split_datasets['train'])}")
        print(f"âœ“ æµ‹è¯•é›†å¤§å°: {len(split_datasets['test'])}")
        
        return split_datasets
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def test_t5_model():
    """æµ‹è¯•T5æ¨¡å‹"""
    print("\nğŸ” æµ‹è¯•T5æ¨¡å‹...")
    
    try:
        # åŠ è½½æ¨¡å‹
        model_name = "t5-small"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        print(f"âœ“ T5æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
        print(f"âœ“ è¯æ±‡è¡¨å¤§å°: {len(tokenizer)}")
        
        # æµ‹è¯•é¢„å¤„ç†
        test_input = "Hello, how are you?"
        test_target = "ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ"
        
        inputs = tokenizer(
            f"translate English to Chinese: {test_input}",
            text_target=test_target,
            max_length=128,
            truncation=True,
            return_tensors="pt"
        )
        
        print(f"âœ“ é¢„å¤„ç†æµ‹è¯•æˆåŠŸ")
        print(f"  è¾“å…¥å½¢çŠ¶: {inputs['input_ids'].shape}")
        print(f"  æ ‡ç­¾å½¢çŠ¶: {inputs['labels'].shape}")
        
        # æµ‹è¯•æ¨ç†
        with torch.no_grad():
            outputs = model.generate(
                inputs['input_ids'],
                max_length=50,
                num_beams=2,
                early_stopping=True
            )
        
        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"âœ“ æ¨ç†æµ‹è¯•æˆåŠŸ")
        print(f"  è¾“å…¥: {test_input}")
        print(f"  è¾“å‡º: {prediction}")
        
        return True
        
    except Exception as e:
        print(f"âŒ T5æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_quick_training():
    """æµ‹è¯•å¿«é€Ÿè®­ç»ƒ"""
    print("\nğŸš€ æµ‹è¯•å¿«é€Ÿè®­ç»ƒ...")
    
    try:
        # åŠ è½½æ•°æ®
        datasets = test_data_loading()
        if datasets is None:
            return False
        
        # ä½¿ç”¨å¾ˆå°çš„æ•°æ®é›†è¿›è¡Œæµ‹è¯•
        tiny_train = datasets["train"].select(range(10))
        tiny_test = datasets["test"].select(range(5))
        
        # è®¾ç½®æ¨¡å‹
        model_name = "t5-small"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        # é¢„å¤„ç†æ•°æ®
        def preprocess_function(examples):
            inputs = [f"translate English to Chinese: {ex}" for ex in examples["english"]]
            targets = [ex for ex in examples["chinese"]]
            model_inputs = tokenizer(
                inputs, text_target=targets, max_length=128, truncation=True
            )
            return model_inputs
        
        tokenized_train = tiny_train.map(
            preprocess_function,
            batched=True,
            remove_columns=tiny_train.column_names,
        )
        
        tokenized_test = tiny_test.map(
            preprocess_function,
            batched=True,
            remove_columns=tiny_test.column_names,
        )
        
        print(f"âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"  è®­ç»ƒæ ·æœ¬: {len(tokenized_train)}")
        print(f"  æµ‹è¯•æ ·æœ¬: {len(tokenized_test)}")
        
        # è®¾ç½®è®­ç»ƒå‚æ•°
        training_args = Seq2SeqTrainingArguments(
            output_dir="./test_model",
            eval_strategy="no",  # ä¸è¿›è¡Œè¯„ä¼°ä»¥èŠ‚çœæ—¶é—´
            learning_rate=5e-5,
            per_device_train_batch_size=2,
            per_device_eval_batch_size=2,
            num_train_epochs=1,  # åªè®­ç»ƒ1ä¸ªepoch
            weight_decay=0.01,
            save_total_limit=1,
            predict_with_generate=True,
            logging_steps=1,
            save_steps=1000,
            report_to=None,
        )
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = Seq2SeqTrainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_train,
            eval_dataset=tokenized_test,
            processing_class=tokenizer,
            data_collator=data_collator,
        )
        
        # å¼€å§‹è®­ç»ƒ
        print("å¼€å§‹å¿«é€Ÿè®­ç»ƒ...")
        trainer.train()
        
        print("âœ“ å¿«é€Ÿè®­ç»ƒå®Œæˆ")
        
        #æµ‹è¯•è®­ç»ƒåçš„æ¨¡å‹
        test_input = "Good morning!"
        inputs = tokenizer(
            f"translate English to Chinese: {test_input}",
            return_tensors="pt"
        )
        
        
        outputs = model.generate(
            inputs['input_ids'],
            max_length=50,
            num_beams=2,
            early_stopping=True
        )
        
        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"âœ“ è®­ç»ƒåæ¨ç†æµ‹è¯•:")
        print(f"  è¾“å…¥: {test_input}")
        print(f"  è¾“å‡º: {prediction}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿè®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_evaluation():
    """æµ‹è¯•è¯„ä¼°åŠŸèƒ½"""
    print("\nğŸ“Š æµ‹è¯•è¯„ä¼°åŠŸèƒ½...")
    
    try:
        # åŠ è½½BLEUè¯„ä¼°å™¨
        metric = evaluate.load("sacrebleu")
        
        # æµ‹è¯•æ•°æ®
        predictions = ["ä½ å¥½ï¼Œä¸–ç•Œï¼", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"]
        references = [["ä½ å¥½ï¼Œä¸–ç•Œï¼"], ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"]]
        
        # è®¡ç®—BLEUåˆ†æ•°
        result = metric.compute(predictions=predictions, references=references)
        print(f"âœ“ BLEUè¯„ä¼°æµ‹è¯•æˆåŠŸ")
        print(f"  BLEUåˆ†æ•°: {result['score']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=== ç¿»è¯‘æ¨¡å‹åŠŸèƒ½æµ‹è¯• ===")
    
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # æµ‹è¯•å„ä¸ªç»„ä»¶
    tests = [
        ("æ•°æ®åŠ è½½", test_data_loading),
        ("T5æ¨¡å‹", test_t5_model),
        ("è¯„ä¼°åŠŸèƒ½", test_evaluation),
        ("å¿«é€Ÿè®­ç»ƒ", test_quick_training),
    ]
    tests = [
        ("å¿«é€Ÿè®­ç»ƒ", test_quick_training),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•: {test_name}")
        print(f"{'='*50}")
        
        try:
            result = test_func()
            results[test_name] = result
            
            if result:
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºé”™: {e}")
            results[test_name] = False
    
    # æ€»ç»“
    print(f"\n{'='*50}")
    print("æµ‹è¯•æ€»ç»“")
    print(f"{'='*50}")
    
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    
    print(f"é€šè¿‡æµ‹è¯•: {passed}/{total}")
    
    for test_name, result in results.items():
        status = "âœ…" if result else "âŒ"
        print(f"{status} {test_name}")
    
    if passed == total:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œå®Œæ•´çš„è®­ç»ƒè„šæœ¬ã€‚")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é—®é¢˜ã€‚")

if __name__ == "__main__":
    main()
