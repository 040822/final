"""
ä¾¿æ·å¯åŠ¨è„šæœ¬
æä¾›é¢„è®¾çš„é…ç½®å’Œå¸¸ç”¨å‘½ä»¤ï¼Œæ–¹ä¾¿å¿«é€Ÿå¼€å§‹è®­ç»ƒå’Œæ¨ç†
"""
import subprocess
import sys
import os
import json
from pathlib import Path

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\n{'='*50}")
    print(f"æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {cmd}")
    print(f"{'='*50}")
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8')
        if result.returncode == 0:
            print("âœ“ å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
            if result.stdout:
                print(result.stdout)
        else:
            print("âœ— å‘½ä»¤æ‰§è¡Œå¤±è´¥")
            if result.stderr:
                print(result.stderr)
        return result.returncode == 0
    except Exception as e:
        print(f"âœ— å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def create_model_config(model_type, output_path):
    """åˆ›å»ºæ¨¡å‹é…ç½®æ–‡ä»¶"""
    configs = {
        'bilstm': {
            'model_type': 'bilstm',
            'tokenizer_type': 'transformers',
            'tokenizer_name': 'bert-base-multilingual-cased',
            'batch_size': 32,
            'learning_rate': 0.001,
            'epochs': 10,
            'embedding_dim': 512,
            'hidden_dim': 512,
            'num_layers': 2,
            'dropout': 0.1,
            'max_len': 128,
            'use_accelerate': True,
            'mixed_precision': 'fp16'
        },
        'transformer': {
            'model_type': 'transformer',
            'tokenizer_type': 'transformers',
            'tokenizer_name': 'bert-base-multilingual-cased',
            'batch_size': 16,
            'learning_rate': 0.0001,
            'epochs': 15,
            'd_model': 512,
            'nhead': 8,
            'num_layers': 6,
            'dropout': 0.1,
            'max_len': 128,
            'use_accelerate': True,
            'mixed_precision': 'fp16'
        },
        'lightweight': {
            'model_type': 'lightweight',
            'tokenizer_type': 'transformers',
            'tokenizer_name': 'bert-base-multilingual-cased',
            'batch_size': 64,
            'learning_rate': 0.0001,
            'epochs': 8,
            'hidden_dim': 512,
            'dropout': 0.1,
            'max_len': 128,
            'use_accelerate': True,
            'mixed_precision': 'fp16'
        },
        'pretrained': {
            'model_type': 'pretrained',
            'tokenizer_type': 'transformers',
            'pretrained_model_name': 'Helsinki-NLP/opus-mt-en-zh',
            'batch_size': 32,
            'learning_rate': 0.00001,
            'epochs': 5,
            'dropout': 0.1,
            'max_len': 128,
            'use_accelerate': True,
            'mixed_precision': 'fp16'
        }
    }
    
    if model_type not in configs:
        print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        return False
    
    config = configs[model_type]
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ“ é…ç½®æ–‡ä»¶å·²åˆ›å»º: {output_path}")
    return True

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    print("è®¾ç½®Pythonç¯å¢ƒ...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
        print("âŒ éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    # å®‰è£…ä¾èµ–
    print("å®‰è£…ä¾èµ–åŒ…...")
    return run_command(
        "pip install -r requirements.txt",
        "å®‰è£…requirements.txtä¸­çš„ä¾èµ–"
    )

def quick_train(model_type='bilstm', data_path='data/translation2019zh_train.json', epochs=5):
    """å¿«é€Ÿè®­ç»ƒ"""
    print(f"å¼€å§‹å¿«é€Ÿè®­ç»ƒ - æ¨¡å‹ç±»å‹: {model_type}")
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config_path = f"configs/{model_type}_config.json"
    os.makedirs("configs", exist_ok=True)
    
    if not create_model_config(model_type, config_path):
        return False
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    cmd = f"""python main_trainer.py \
        --train_data_path "{data_path}" \
        --model_type {model_type} \
        --epochs {epochs} \
        --batch_size 16 \
        --learning_rate 0.0001 \
        --log_dir "logs/{model_type}" \
        --model_dir "models/{model_type}" \
        --cache_dir "cache" \
        --sample_ratio 0.1 \
        --use_accelerate \
        --mixed_precision fp16 \
        --early_stopping 3"""
    
    return run_command(cmd, f"è®­ç»ƒ{model_type}æ¨¡å‹")

def quick_inference(model_path, text="Hello, how are you?"):
    """å¿«é€Ÿæ¨ç†"""
    print(f"ä½¿ç”¨æ¨¡å‹è¿›è¡Œå¿«é€Ÿæ¨ç†")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    cmd = f'python inference_new.py translate --model_path "{model_path}" --text "{text}"'
    return run_command(cmd, "å¿«é€Ÿç¿»è¯‘æµ‹è¯•")

def batch_translate(model_path, input_file, output_file):
    """æ‰¹é‡ç¿»è¯‘"""
    print(f"æ‰§è¡Œæ‰¹é‡ç¿»è¯‘")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return False
    
    cmd = f'python inference_new.py batch --model_path "{model_path}" --input_file "{input_file}" --output_file "{output_file}"'
    return run_command(cmd, "æ‰¹é‡ç¿»è¯‘")

def evaluate_model(model_path, test_data_path, output_file=None):
    """è¯„ä¼°æ¨¡å‹"""
    print(f"è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    if not os.path.exists(test_data_path):
        print(f"âŒ æµ‹è¯•æ•°æ®ä¸å­˜åœ¨: {test_data_path}")
        return False
    
    cmd = f'python inference_new.py evaluate --model_path "{model_path}" --data_path "{test_data_path}"'
    if output_file:
        cmd += f' --output_file "{output_file}"'
    
    return run_command(cmd, "æ¨¡å‹è¯„ä¼°")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è‹±è¯‘ä¸­ç¿»è¯‘ç³»ç»Ÿå¯åŠ¨å™¨")
    print("=" * 50)
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python launcher.py setup                    # è®¾ç½®ç¯å¢ƒ")
        print("  python launcher.py train [model_type]       # å¿«é€Ÿè®­ç»ƒ")
        print("  python launcher.py inference [model_path]   # å¿«é€Ÿæ¨ç†")
        print("  python launcher.py batch [model_path] [input_file] [output_file]  # æ‰¹é‡ç¿»è¯‘")
        print("  python launcher.py evaluate [model_path] [test_data]  # è¯„ä¼°æ¨¡å‹")
        print("\næ”¯æŒçš„æ¨¡å‹ç±»å‹: bilstm, transformer, lightweight, pretrained")
        return
    
    command = sys.argv[1]
    
    if command == "setup":
        setup_environment()
    
    elif command == "train":
        model_type = sys.argv[2] if len(sys.argv) > 2 else 'bilstm'
        data_path = sys.argv[3] if len(sys.argv) > 3 else 'data/translation2019zh_train.json'
        epochs = int(sys.argv[4]) if len(sys.argv) > 4 else 5
        quick_train(model_type, data_path, epochs)
    
    elif command == "inference":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›æ¨¡å‹è·¯å¾„")
            return
        model_path = sys.argv[2]
        text = sys.argv[3] if len(sys.argv) > 3 else "Hello, how are you?"
        quick_inference(model_path, text)
    
    elif command == "batch":
        if len(sys.argv) < 5:
            print("âŒ è¯·æä¾›æ¨¡å‹è·¯å¾„ã€è¾“å…¥æ–‡ä»¶å’Œè¾“å‡ºæ–‡ä»¶")
            return
        model_path = sys.argv[2]
        input_file = sys.argv[3]
        output_file = sys.argv[4]
        batch_translate(model_path, input_file, output_file)
    
    elif command == "evaluate":
        if len(sys.argv) < 4:
            print("âŒ è¯·æä¾›æ¨¡å‹è·¯å¾„å’Œæµ‹è¯•æ•°æ®è·¯å¾„")
            return
        model_path = sys.argv[2]
        test_data_path = sys.argv[3]
        output_file = sys.argv[4] if len(sys.argv) > 4 else None
        evaluate_model(model_path, test_data_path, output_file)
    
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")

if __name__ == "__main__":
    main()
